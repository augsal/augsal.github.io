<style>
    /* Style for slider */
    .slider {
        -webkit-appearance: none;
        width: 100%;
        height: 10px;
        border-radius: 5px;
        background: #d3d3d3;
        outline: none;
        opacity: 0.7;
        -webkit-transition: .2s;
        transition: opacity .2s;
        position: relative;
    }

    /* Style for slider thumb */
    .slider::-webkit-slider-thumb {
        -webkit-appearance: none;
        appearance: none;
        width: 20px;
        height: 20px;
        border-radius: 50%;
        background: #4CAF50;
        cursor: pointer;
        position: relative;
        z-index: 3;
    }

    /* Style for slider ticks */
/*    .slider-container::before {
        content: "";
        position: absolute;
        top: 50%;
        left: 0;
        width: 100%;
        height: 1px;
        background-color: #999;
        z-index: 1;
    }*/

    .slider-ticks {
        position: relative;
        z-index: 2;
        width: 100%;
        height: 20px;
    }

    .slider-ticks::after {
        content: "";
        display: block;
        position: absolute;
        left: 0;
        right: 0;
        height: 2px;
        background-color: #999;
    }

    .slider-tick {
        position: absolute;
        width: 2px;
        height: 9px;
        background-color: #999;
        z-index: 2;
    }

    .slider-tick:nth-child(2) {
        left: calc(50.00% - 0.5px);
    }

    .slider-tick:nth-child(3) {
        left: calc(100.0% - 0.5px);
    }
</style>



<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Data Augmentation via Latent Diffusion for Saliency Prediction</title>
<link href="style.css" rel="stylesheet">
<!--<script type="text/javascript" src="./ptp_files/jquery.mlens-1.0.min.js"></script>-->
<!--<script type="text/javascript" src="./ptp_files/jquery.js"></script>-->
<!--  <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js" type="text/javascript"></script>-->
<script type="text/javascript" src="./sal_diff_files/cat_hat.js"></script>
</head>

<body>
<div class="content">
    <h1><strong>Data Augmentation via Latent Diffusion for Saliency Prediction </strong> <br> </h1>
  <p id="authors">Interactive Visualization<br>
  <p id="authors">Anonymous authors<br>
  <span style="font-size: 18px">ECCV 2024 Submission - Paper ID: 10071
  </span></p>

</div>


<div class="content">
  <h2 style="text-align:center;"></h2>
  <p> Saliency prediction models are constrained by the limited diversity and quantity of labeled data. Standard data augmentation techniques such as rotating, and cropping change the scene composition hence affecting saliency. In this work, we propose a novel data augmentation method for deep saliency prediction that involves editing natural images while retaining the complexity and variability of real-world visual scenes. Since saliency depends on both high-level and low-level features such as semantics and photometric properties, our approach involves learning both by incorporating photometric and semantic attributes such as color, contrast, brightness, and class. To that end, we introduce a saliency-guided cross-attention mechanism that enables targeted edits on the photometric properties, thereby enhancing saliency within specific image regions and providing controllability to our model in the context of saliency prediction. Our saliency predictions are highly aligned with human visual attention patterns in the edited images, as validated by a user study. 
  </p>
</div>
<div class="content">
  <h2 style="text-align:center;"></h2>
    <strong> TL;DR </strong> We use latent diffusion to augment data for saliency prediction. We show our method improves the performance of existing saliency models. Moreover, we learn multilevel features that improve saliency prediction.
  </p>
</div>
<div class="content">
<h2>Augmentation</h2>
<p>We provide an overview of our augmentation method below.</p>
<p>Using our method, we amplify the contrast of the giraffe in the original image. We also enhance the brightness as another type of augmentation. Our model can constrain excessively strong edits to prevent unnatural results.</p>
<div class="cat-hat-main">
    <div class="mybox">
        <video controls class="cat-hat-img" id="video0" style="width:1024px;height:512px;">
            <source src="./sal_diff_files/augment.mp4" type="video/mp4">
        </video><br>
        <p style="text-align:center;">Augmentations</p>
    </div>
    
</div>
<br>
</div>
<div class="content">

<h2>Saliency Guided Cross-Attention Mechanism</h2>
<p>We use a saliency guided cross-attention mechanism to localize the region that we aim to edit.</p>
<p>We extract cross-attention features from the input image and prompt, then multiply them with the initial saliency to create spatial attention maps. Each word generates a spatial attention map, and we select the one with the highest sum as <span style="color: darkred; font-weight: bold;">the target editing region</span> . These selected spatial maps are shown in Figure-4 in the main paper. We utilize prompts from the MS-COCO dataset and modify them as described in Section 3.5 during editing. We use the target region to edit and the edited image pairs to train the models with augmentation which we explain in the following section.</p>
<div class="cat-hat-main">
    <div class="mybox">
        <video controls class="cat-hat-img" id="video1" style="width:1024px;height:512px;">
            <source src="./sal_diff_files/explain-crossattn.mp4" type="video/mp4">
        </video><br>
        <p style="text-align:center;">Saliency Guided Cross-Attention Mechanism</p>
    </div>
    
</div>
<br>
</div>
<div class="content">


<h2>Training with Augmentations</h2>
<p>We show how we train the saliency prediction models with our augmented images.</p>
<p> Given an image, saliency ground-truth and the <span style="color: darkred; font-weight: bold;">target region to edit</span>, we generate the image edits using our augmentation method. Then, we predict saliency for the original and the edited images respectively. Since our edits enhance saliency in the edited regions, we calculate the Binary Cross Entropy (BCE) between the saliency predictions of the original and edited images. That is, we penalize the models if they underestimate the saliency of the edited regions. We validate that our editing method enhances the saliency in the edited regions by a user study. </p>
<div class="cat-hat-main">
    <div class="mybox">
        <video controls class="cat-hat-img" id="video2" style="width:1024px;height:512px;">
            <source src="./sal_diff_files/explain-loss.mp4" type="video/mp4">
        </video><br>
        <p style="text-align:center;">Training with Augmentations</p>
    </div>
    
</div>
<br>
</div>
<div class="content">


  <h2 style="text-align:center;"></h2>
Saliency is influenced by contrast<sup><a href="#ref3">[3]</a></sup>, brightness<sup><a href="#ref2">[2]</a></sup>, and color<sup><a href="#ref4">[4]</a></sup><sup><a href="#ref5">[5]</a></sup> as evidenced by cognitive studies on human visual attention<sup><a href="#ref1">[1]</a></sup>. We focus on photometric edits that enhance the saliency of the most salient region that corresponds to a word from the prompt. We provide two examples for each edit in the following sections. Please use the sliders on the right to see the generated image edits and their saliency maps. We refer to the supplementary material for the comparison with the baselines.
  </p>
</div>
<div class="content">


  <h2>Contrast</h2>
  <p>We show the edited images at different intensity levels for enhancing contrast on the left and their corresponding saliency predictions on the right. 
</p>

    <p> Using our method, we amplify the contrast of the object that man is holding in the image below. Observe the shift in saliency towards the region with high contrast. Our model is able to enhance and thus, control the saliency of the edited region.
       </p>
    <div class="cat-hat-main">

        <div class="mybox">
         <img class="cat-hat-img" id="image0" src="./sal_diff_files/contrast-1/COCO_val2014_000000025860_a1.jpg" style="width:256px;height:256px;"><br>
         <p style="text-align:center;">   Image with edited contrast </p>
        </div>
        <hr><hr><hr><hr>
        <div class="mybox">
         <img class="cat-hat-img" id="image0-sal-map" src="./sal_diff_files/contrast-1/man_a1.png" style="width:256px;height:256px;">
         <p style="text-align:center;">  Our predictions  </p>
      </div>
         <br>
                <div class="cat-hat-text">
                    <div class="slider-container">
                        <input type="range" min="1" max="3" value="1" class="slider" id="range0">
                    </div>
                    <div class="slider-ticks">
                        <div class="slider-tick"></div>        
                        <div class="slider-tick"></div>
                        <div class="slider-tick"></div>
                    </div>

                    <div style="display: flex; justify-content: space-between;">
                        <label for="range3" style="text-align: left;">1</label>
                        <label for="range3" style="text-align: center;">2</label>
                        <label for="range3" style="text-align: right;">3</label>
                    </div>
                    <p>Please use the slider to visualize the changes in the saliency based on the photometric changes in the image.</p>
                </div>
        </div>
  <br>
<!-- </div>
<div class="content"> -->

  <h2>Contrast </h2>
  <p>We show the edited images at different intensity levels for enhancing contrast on the left and their corresponding saliency predictions on the right.  </p>
    <p> Using our method, we can amplify the contrast of the dog in the image below. Although the items on the desk remain salient, the dog gathers more attention as the edit intensity increases. Our model is able to control the saliency prediction over the edited region.
       </p>
    <div class="cat-hat-main">

      <div class="mybox">
        <img class="cat-hat-img" id="image1" src="./sal_diff_files/contrast-2/COCO_val2014_000000061735_a1.jpg" style="width:256px;height:256px;">
        <p style="text-align:center;">   Image with edited contrast </p>
      </div>
      <hr><hr><hr><hr>
      <div class="mybox">
      <img class="cat-hat-img" id="image1-sal-map" src="./sal_diff_files/contrast-2/dog_a1.png" style="width:256px;height:256px;">
      <p style="text-align:center;">   Our predictions </p>
      </div>
    
         <br>
                  <div class="cat-hat-text">
               <div class="slider-container">
                <input type="range" min="1" max="3" value="1" class="slider" id="range1">
                </div>
                <div class="slider-ticks">
                    <div class="slider-tick"></div>        
                    <div class="slider-tick"></div>
                    <div class="slider-tick"></div>
                </div>

                <div style="display: flex; justify-content: space-between;">
                    <label for="range3" style="text-align: left;">1</label>
                    <label for="range3" style="text-align: center;">2</label>
                    <label for="range3" style="text-align: right;">3</label>
                </div>
                <p>Please use the slider to visualize the changes in the saliency based on the photometric changes in the image.</p>
                </div>
        </div>
  <br>
</div>
<div class="content">

  <h2>Brightness </h2>
  <p>We show the edited images at different intensity levels for enhancing brightness on the left and their corresponding saliency predictions on the right.  </p>

    <p> We enhance the brightness of the cat in the image below. Note that, the attention shifts towards the brighter regions which aligns with our edited regions. Our model is able to predict the saliency in a controllable and interpretable manner by following the brightness change towards the rear end of the cat.
       </p>
    <div class="cat-hat-main">
      <div class="mybox">
         <img class="cat-hat-img" id="image2" src="./sal_diff_files/brightness-1/COCO_val2014_000000028273_a1.jpg" style="width:256px;height:256px;">
         <p style="text-align:center;">   Image with edited brightness </p>
        </div>
        <hr><hr><hr><hr>
        <div class="mybox">
        <img class="cat-hat-img" id="image2-sal-map" src="./sal_diff_files/brightness-1/cat_a1.png" style="width:256px;height:256px;">
        <p style="text-align:center;">   Our predictions </p>
      </div>
       <br>
                  <div class="cat-hat-text">
               <div class="slider-container">
                <input type="range" min="1" max="3" value="1" class="slider" id="range2">
                </div>
                <div class="slider-ticks">
                    <div class="slider-tick"></div>        
                    <div class="slider-tick"></div>
                    <div class="slider-tick"></div>
                </div>

                <div style="display: flex; justify-content: space-between;">
                    <label for="range3" style="text-align: left;">1</label>
                    <label for="range3" style="text-align: center;">2</label>
                    <label for="range3" style="text-align: right;">3</label>
                </div>
                <p>Please use the slider to visualize the changes in the saliency based on the photometric changes in the image.</p>
                </div>
        </div>
  <br>
<!-- </div>
<div class="content"> -->

  <h2>Brightness </h2>
  <p>We show the edited images at different intensity levels for enhancing brightness on the left and their corresponding saliency predictions on the right.  </p>


    <p> We amplify the brightness of the pizzas in the image below. Although the pizzas remain salient, we show the saliency of the bottle on the left and the glass in the middle decrease.
       </p>
    <div class="cat-hat-main">

      <div class="mybox">
         <img class="cat-hat-img" id="image3" src="./sal_diff_files/brightness-2/COCO_val2014_000000251920_a1.jpg" style="width:256px;height:256px;"> 
         <p style="text-align:center;">   Image with edited brightness </p>
         </div>
         <hr><hr><hr><hr>
         <div class="mybox">
         <img class="cat-hat-img" id="image3-sal-map" src="./sal_diff_files/brightness-2/pizza_a1.png" style="width:256px;height:256px;">
         <p style="text-align:center;">   Our predictions </p>
        </div>
         <br>
         <div class="cat-hat-text">
               <div class="slider-container">
                <input type="range" min="1" max="3" value="1" class="slider" id="range3">
                </div>
                <div class="slider-ticks">
                    <div class="slider-tick"></div>        
                    <div class="slider-tick"></div>
                    <div class="slider-tick"></div>
                </div>

                <div style="display: flex; justify-content: space-between;">
                    <label for="range3" style="text-align: left;">1</label>
                    <label for="range3" style="text-align: center;">2</label>
                    <label for="range3" style="text-align: right;">3</label>
                </div>
                <p>Please use the slider to visualize the changes in the saliency based on the photometric changes in the image.</p>
                </div>
        </div>
  <br>
</div>
<div class="content">

  <h2>Color</h2>
  <p>We show the edited images at different intensity levels for changing the color of the selected region to pink on the left and their corresponding saliency predictions on the right.  </p>

    <p> Using our method, we change the color of the toy sitting on the chair in the image below. The attention on the face of the toy increases according to the intensity of the color edit.
       </p>
    <div class="cat-hat-main">

      <div class="mybox">
         <img class="cat-hat-img" id="image4" src="./sal_diff_files/color-1/COCO_val2014_000000432125_a1.jpg" style="width:256px;height:256px;"> 
         <p style="text-align:center;">   Image with edited color </p>
      </div>
      <hr><hr><hr><hr>
      <div class="mybox">
         <img class="cat-hat-img" id="image4-sal-map" src="./sal_diff_files/color-1/pink_a1.png" style="width:256px;height:256px;">
         <p style="text-align:center;">   Our predictions </p>
      </div>
         <br>
         <div class="cat-hat-text">
               <div class="slider-container">
                <input type="range" min="1" max="3" value="1" class="slider" id="range4">
                </div>
                <div class="slider-ticks">
                    <div class="slider-tick"></div>        
                    <div class="slider-tick"></div>
                    <div class="slider-tick"></div>
                </div>

                <div style="display: flex; justify-content: space-between;">
                    <label for="range3" style="text-align: left;">1</label>
                    <label for="range3" style="text-align: center;">2</label>
                    <label for="range3" style="text-align: right;">3</label>
                </div>
                <p>Please use the slider to visualize the changes in the saliency based on the photometric changes in the image.</p>
                </div>
        </div>
  <br>
<!-- </div>
<div class="content"> -->

  <h2>Color </h2>
  <p>We show the edited images at different intensity levels for changing the color of the selected region to green on the left and their corresponding saliency predictions on the right.  </p>

    <p> Here, we change the color of traffic light to green in the image below. Observe that, the saliency disperses towards the edited region. As the color intensifies, our odel is able to enhance the saliency prediction within these color-edited regions.

       </p>
    <div class="cat-hat-main">

      <div class="mybox">
         <img class="cat-hat-img" id="image5" src="./sal_diff_files/color-2/COCO_val2014_000000289222_a1.jpg" style="width:256px;height:256px;"> 
         <p style="text-align:center;">   Image with edited color </p>
      </div>
      <hr><hr><hr><hr>
      <div class="mybox">
         <img class="cat-hat-img" id="image5-sal-map" src="./sal_diff_files/color-2/tr_a1.png" style="width:256px;height:256px;">
         <p style="text-align:center;">   Our predictions </p>
        </div>
         <br>
         <div class="cat-hat-text">
               <div class="slider-container">
                <input type="range" min="1" max="3" value="1" class="slider" id="range5">
                </div>
                <div class="slider-ticks">
                    <div class="slider-tick"></div>        
                    <div class="slider-tick"></div>
                    <div class="slider-tick"></div>
                </div>

                <div style="display: flex; justify-content: space-between;">
                    <label for="range3" style="text-align: left;">1</label>
                    <label for="range3" style="text-align: center;">2</label>
                    <label for="range3" style="text-align: right;">3</label>
                </div>
                <p>Please use the slider to visualize the changes in the saliency based on the photometric changes in the image.</p>
                </div>
        </div>
  <br>
</div>
<div class="content">

  <h2>Applications of our method</h2>
  <p>We show the edited images at different intensity levels for enhancing contrast of the selected region on the left and their corresponding saliency predictions on the right.  </p>


    <p> We show a practical application of our model in the field of advertising, particularly in enhancing the visual appeal of products in the image below. Consider an advertisement featuring a hamburger alongside fries. Using our model, we can selectively increase the contrast on the hamburger, drawing more attention to the edited region. Assessing the saliency of such generated image edits in capturing viewer visual attention would require user studies which are costly and time-consuming. However, our method simultaneously produces the saliency map as we generate the image edit. This immediate feedback allows advertisers to fine-tune their image edits in real-time, ensuring that the focal product, like the hamburger in this scenario, stands out from other elements, such as the fries. Hence, we enable advertisers to make human visual attention-driven decisions about visual edits, optimizing the impact of their advertisements without the need for time-consuming user studies. This not only streamlines the process of creating visually compelling advertisements but also enhances the likelihood of capturing and retaining consumer attention.
       </p>
    <div class="cat-hat-main">

      <div class="mybox">
         <img class="cat-hat-img" id="image6" src="./sal_diff_files/hamburger/COCO_val2014_000000100083_a1.jpg" style="width:256px;height:256px;"> 
         <p style="text-align:center;">   Image with edited contrast </p>
         </div>
        <hr><hr><hr><hr>
      <div class="mybox">
         <img class="cat-hat-img" id="image6-sal-map" src="./sal_diff_files/hamburger/burger_a1.png" style="width:256px;height:256px;">
         <p style="text-align:center;">   Our predictions </p>
      </div>
         <br>
         <div class="cat-hat-text">
               <div class="slider-container">
                <input type="range" min="1" max="3" value="1" class="slider" id="range6">
                </div>
                <div class="slider-ticks">
                    <div class="slider-tick"></div>        
                    <div class="slider-tick"></div>
                    <div class="slider-tick"></div>
                </div>

                <div style="display: flex; justify-content: space-between;">
                    <label for="range3" style="text-align: left;">1</label>
                    <label for="range3" style="text-align: center;">2</label>
                    <label for="range3" style="text-align: right;">3</label>
                </div>
                <p>Please use the slider to visualize the changes in the saliency based on the photometric changes in the image.</p>
                </div>
        </div>
  <br>





</div>



<div class="content">


<!-- References Section -->
<div id="references">
    <h2>References</h2>
    <ol>
        <!-- Add more list items for each reference -->
        <li id="ref1">Wolfe, J., Horowitz, T., What attributes guide the deployment of visual attention and how do they do it?, <i>Nature Reviews Neuroscience</i>, 5, 2004. </li>
        <li id="ref2">Ochiai, N., & Sato, M. , Effects of Surrounding Brightness on Visual Search for Safety Colors. <i>Color Research and Application</i>, 30(6), 2005. </li>

        <li id="ref3">Pashler, H., Dobkins, K. & Huang L., Is contrast just another feature for visual selective attention?, <i>Vision Research</i>, 44(12), 2004.</li>
        <li id="ref4">Nagy, A. L. & Sanchez, R. R.  Critical color differences determined with a visual search task, <i>Journal of the Optical Society of America</i>, 1990.</li>
        <li id="ref5">Bauer, B., Jolicoeur, P. & Cowan, W. B.  Visual search for colour targets that are or are not linearly-separable from distractors. <i>Vision Research</i>, 1996.</li>

    </ol>
</div>

</div>

</div>
</body>
</html>
